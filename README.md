# Dual Thinking and Perceptual Analysis of Deep Learning Models using Human Adversarial Examples

Paper link - https://arxiv.org/abs/2406.06967

**Human Confusion Dataset** 

The dataset can be downloaded from the link below.

[human-confusion-dataset.0.3.zip](https://github.com/kailasdayanandan/dual_thinking/releases/download/v0.0.3-dataset-release/human-confusion-dataset.0.3.zip)

**Code Setup** 

Download the dataset, extract the contents and copy the contents to data folder.

Run python main_release.py

**Example Scripts** 

Examples of images in dataset and different categories of errors are shown in the below notebook.

[example_scripts/Exploring_Dataset.ipynb](https://github.com/kailasdayanandan/dual_thinking/blob/main/example_scripts/Exploring_Dataset.ipynb)

The script to reproduce results and figures in paper are shown in the below notebook.

[example_scripts/Results.ipynb](https://github.com/kailasdayanandan/dual_thinking/blob/main/example_scripts/Results.ipynb)

**Citing Our Work** 

To cite this project, please use the citation below:
```
@misc{dayanandan2024dual,
    title={Dual Thinking and Logical Processing - Are Multi-modal Large Language Models Closing the Gap with Human Vision ?},
    author={Kailas Dayanandan, Nikhil Kumar, Anand Sinha and Brejesh Lall},
    year={2024},
    eprint={2406.06967},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```
